---
title: "Homework 3"
author: "Gauri Bhatkhande"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "botttom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```
This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user/order variables -- and item variables. `r variable.names(instacart)`

How many aisles and which are most items from? 
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```
Lets make a plot 

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle), 
    aisle = fct_reorder(aisle, n)
  )%>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Lets make a table 

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
    knitr::kable()
```
Apples vs ice cream 

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream"))%>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
pivot_wider(
  names_from = order_dow, 
  values_from = mean_hour
)
```

## Problem 2

Loading the dataset
```{r}
accelero_data = read_csv(file = "./Data/accel_data.csv")
```

Tidying and wrangling the dataset

```{r}
accelero_data = janitor::clean_names(accelero_data) %>%
                pivot_longer(
                   activity_1:activity_1440,
                   names_to = "activity_for_minute",
                   values_to = "activity_count") %>%
  separate(activity_for_minute, c("word", "minute_of_the_day"), "_") %>%
  select(-word) %>%
  mutate(
    minute_of_the_day = as.numeric(minute_of_the_day)
  ) %>%
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
        )%>%
  mutate(day_type = case_when(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "Weekday",
                              day %in% c("Saturday", "Sunday") ~ "Weekend")
        )
accelero_data
```
The variables in the data are `r variable.names(accelero_data)`. There are `r nrow(accelero_data)` rows (observations) and `r ncol(accelero_data)` columns in the dataset. The number of rows or observations signifies activity count for each minute of the day for each day of the week for 5 weeks (35 days). 

Making a table of total activity for each day of the week

```{r}
accelero_data %>%
  group_by(week, day) %>%
  summarize(total_activity = sum(activity_count)) %>%
 knitr::kable()
```
He tends to have more physical activity during the weekdays than the weekends for the first couple of weeks. Later his activity on weekends increases. However, during the Saturdays of the 4th and 5th weeks, he had barely any activity. They could have been rest days. 


Making a plot for the activity time course per day
```{r}
accelero_data %>%
  ggplot(aes(x = minute_of_the_day, y = activity_count, color = day)) + geom_line() +
  labs(
      title = "Activity time courses per day",
    x = "Minute of the day",
    y = "Activity count",
    caption = "Data from Advanced Cardiac Care Center of Columbia University Medical Center"
  ) +
  theme(legend.position = "bottom")
```


Except for Sunday, Most of the activity is higher during the latter half of the day. It appears that on Fridays the activity counts were the highest among all days for the later half of the day. On Sunday the activity is high towards the middle of the day. 


## Problem 3

```{r}
library(p8105.datasets)
data("ny_noaa")

```

### Description of the data

The dataset has `r nrow(ny_noaa)` rows (observations) and `r ncol(ny_noaa)` columns. The variables included are `r variable.names(ny_noaa)`. It has information about the weather including precipitation, snowfall, snow depth, maximum and minimum temperatures observed on different dates. 


```{r}
summary(ny_noaa)

```
The missing values should be taken into consideration before making the ggplots 

**Data cleaning and Creating separate variables for year, month, date. Ensuring observations are in reasonable units.**

```{r}
ny_noaa_clean = janitor::clean_names(ny_noaa) %>%
separate (date, c("year", "month", "date"), "-") %>%
  mutate(
    tmin = as.numeric(tmin), 
    tmax = as.numeric(tmax), 
    year = as.numeric(year),
    month = as.numeric(month),
    date = as.numeric(date)) %>%
  mutate(
    prcp = prcp/10,
    tmax = tmax/10,
    tmin = tmin/10 )

head(ny_noaa_clean)
```
**For snowfall, to find the most commonly observed values? Why?**

```{r}
ny_noaa_clean %>%
  count(snow, sort = TRUE )%>%
  slice (1:5)
  
```

The most commonly observed value is 0 mm. This is because for most of the time in the year, it does not snow and hence it is 0. The three most commonly observed values are 25 (31022), 13 (23095), 51 (18274) (when we don't consider the times when there was no snowfall (0) and missing values (NA)).
 

Creating plot showing the average max temperature in January and in July in each station across years

```{r}
p3_plot1 = ny_noaa_clean %>%
  filter(month %in% c(1,7)) %>%
  group_by(id,year,month) %>%
  summarize(mean_tmax = mean(tmax,na.rm=TRUE))

  ggplot(p3_plot1,aes(x = year, y = mean_tmax)) +
  geom_point(aes(colour = id),alpha = 0.5) + 
  geom_smooth() +facet_grid(. ~month)

ggsave("problem3_plot1.png")

```
There are a few outliers between the years 1980 and 1990 in both the months. There appears to be a lot of fluctuation in temperatures in January. The average tmax seems to change a lot in the month of January over the years. The average temperature (considering that January is supposed to be a cold season), has increased. 

There appears to be a sudden increase in the month of July towards 2010. 
The fluctuating temperatures in January and the warmer temperatures in July are indicative of climate change. 


**Making a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and (ii)  a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year. Used patchwork**

```{r}
library (patchwork)
plot1 = ggplot(ny_noaa_clean, aes(x=tmin,y=tmax) ) + geom_hex()

plot2 = ny_noaa_clean %>%
        filter(snow>0, snow<100) %>%
        ggplot( aes(x = year, y = snow)) + geom_violin(aes(group = year))

plot1 / plot2
```






